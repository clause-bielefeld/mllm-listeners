{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import csv\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from configuration import Config\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hls to rgb convertion, data parsing and building data dicitonary out of original data \n",
    "\n",
    "def hls_values_to_float(hls):\n",
    "    h, l, s = hls\n",
    "    h_out = h / 359\n",
    "    l_out = l / 100\n",
    "    s_out = s/ 100\n",
    "    return h_out, l_out, s_out\n",
    "\n",
    "def parse_entry(e):\n",
    "\n",
    "    identifier = f\"{e['gameid']}:{e['roundNum']}\"\n",
    "    success = e['outcome'] == 'true'\n",
    "    role = e['role']\n",
    "    source = e['source']\n",
    "    condition = e['condition']\n",
    "\n",
    "    patches = [\n",
    "        (\n",
    "            e['clickStatus'],\n",
    "            tuple(map(int, [e['clickColH'], e['clickColL'], e['clickColS']])),\n",
    "        ), # HLS values of patch clicked by listener\n",
    "        (\n",
    "            e['alt1Status'],\n",
    "            tuple(map(int, [e['alt1ColH'], e['alt1ColL'], e['alt1ColS']])),\n",
    "        ), # HLS values for 1st alternative\n",
    "        (\n",
    "            e['alt2Status'],\n",
    "            tuple(map(int, [e['alt2ColH'], e['alt2ColL'], e['alt2ColS']]))\n",
    "        ), # HLS values for 2nd alternative\n",
    "    ]\n",
    "\n",
    "    d1, d2, t = sorted(patches, key=lambda x: x[0])\n",
    "    assert t[0] == 'target'\n",
    "    hls_values = (t[1], d1[1], d2[1])\n",
    "\n",
    "    speaker_positions = [None, None, None]\n",
    "    listener_positions = [None, None, None]\n",
    "\n",
    "    status_locations = [\n",
    "        (e['clickStatus'], e['clickLocS'], e['clickLocL']),\n",
    "        (e['alt1Status'], e['alt1LocS'], e['alt1LocL']),\n",
    "        (e['alt2Status'], e['alt2LocS'], e['alt2LocL']),\n",
    "    ]\n",
    "\n",
    "    for status, loc_s, loc_l in status_locations:\n",
    "        if status == 'target':\n",
    "            speaker_positions[0] = loc_s\n",
    "            listener_positions[0] = loc_l\n",
    "        elif status == 'distr1':\n",
    "            speaker_positions[1] = loc_s\n",
    "            listener_positions[1] = loc_l\n",
    "        elif status == 'distr2':\n",
    "            speaker_positions[2] = loc_s\n",
    "            listener_positions[2] = loc_l\n",
    "        \n",
    "    expression = e['contents']\n",
    "\n",
    "    return {\n",
    "        'identifier': identifier,\n",
    "        'role': role,\n",
    "        'source': source,\n",
    "        'hls_values': hls_values,\n",
    "        'expression': expression,\n",
    "        'condition': condition,\n",
    "        'success': success,\n",
    "        's_order_t_distr1_distr2': speaker_positions,\n",
    "        'l_order_t_distr1_distr2': listener_positions\n",
    "    }\n",
    "\n",
    "def build_data_dict(data_path):\n",
    "    all_data = []\n",
    "    with open(data_path, 'r') as file:\n",
    "        csv_file = csv.DictReader(file)\n",
    "        for i, row in enumerate(csv_file):\n",
    "            row_data = dict(row)\n",
    "            all_data.append({'idx':i, **parse_entry(row_data)})\n",
    "    return all_data\n",
    "\n",
    "# filtering and saving data splits\n",
    "\n",
    "def filter_raw_data(data, args):\n",
    "    if not args.keep_failed:\n",
    "        data = [d for d in data if d['success']]\n",
    "    if not args.keep_listener_turns:\n",
    "        data = [d for d in data if d['role'] == 'speaker']\n",
    "    if not args.keep_non_human:\n",
    "        data = [d for d in data if d['source'] == 'human']\n",
    "    return data\n",
    "\n",
    "def save_data_splits(data, args):\n",
    "    out_dir = osp.abspath(args.output_dir)\n",
    "    if not osp.isdir(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    for split_data, name in zip(data, ['train', 'val', 'test']):\n",
    "        out_path = osp.join(out_dir, f'{name}.json')\n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(split_data, f)\n",
    "\n",
    "        print(f'Saved {name}.json to {out_path}.')\n",
    "\n",
    "# loading split data \n",
    "\n",
    "def load_data_splits(json_dir):\n",
    "    split_files = ['train.json', 'val.json', 'test.json']\n",
    "    split_names = ['train', 'val', 'test']\n",
    "    preprocessed_data = {}\n",
    "\n",
    "    for split_file, split_name in zip(split_files, split_names):\n",
    "        split_file_path = osp.join(json_dir, split_file)\n",
    "        if osp.exists(split_file_path):\n",
    "            with open(split_file_path, 'r') as f:\n",
    "                preprocessed_data[split_name] = json.load(f)  \n",
    "                print(f'Loaded {split_file}.')\n",
    "        else:\n",
    "            print(f'{split_file} not found in {json_dir}.')\n",
    "\n",
    "    return preprocessed_data\n",
    "\n",
    "# further processing of split data // filtering out unsuccessful rounds\n",
    "\n",
    "def filter_split_data(split_data):\n",
    "    filtered_data = {}\n",
    "    for split_name, split in split_data.items():\n",
    "        if split_name in ['train', 'val', 'test']:\n",
    "            filtered_split = []\n",
    "            for entry in split:\n",
    "                if entry.get('success', False): #only include successful rounds\n",
    "                    entry['split'] = split_name\n",
    "                    filtered_split.append(entry)\n",
    "            filtered_data[split_name] = filtered_split\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "# creating final data needed for model input: round information (gameid, roundnum, condition, split, hls values, speaker and listener order of patches) & conversation\n",
    "\n",
    "def create_final_data_sctructure(data):\n",
    "    games = {}\n",
    "\n",
    "    for entry in data:\n",
    "        identifier = entry['identifier']\n",
    "        gameid, roundnum = identifier.split(':')\n",
    "        roundnum = int(roundnum)\n",
    "        condition = entry['condition']\n",
    "        success = entry['success']\n",
    "        role = entry['role']\n",
    "        hls_values = entry['hls_values']\n",
    "        s_order_t_distr1_distr2 = [int(x)-1 for x in entry['s_order_t_distr1_distr2']]  # offset\n",
    "        l_order_t_distr1_distr2 = [int(x)-1 for x in entry['l_order_t_distr1_distr2']]  # offset\n",
    "\n",
    "        if identifier not in games:\n",
    "            games[identifier] = {\n",
    "                'identifier': identifier,\n",
    "                'gameid': gameid,\n",
    "                'roundNum': roundnum,\n",
    "                'condition': condition,\n",
    "                'success': success,\n",
    "                'hls_values': hls_values,\n",
    "                's_order_t_distr1_distr2': s_order_t_distr1_distr2,\n",
    "                'l_order_t_distr1_distr2': l_order_t_distr1_distr2,\n",
    "                'conversation': [],\n",
    "                'n_utterances': 0\n",
    "            }\n",
    "\n",
    "        conversation = games[identifier]['conversation']\n",
    "        conversation_entry = (role, entry['expression'], None)\n",
    "        conversation.append(conversation_entry)\n",
    "        games[identifier]['n_utterances'] += 1\n",
    "\n",
    "    final_data = list(games.values())\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    originaldata_location = osp.join(config.colorpatch_data, 'behavioralAnalysis', 'humanOutput'),\n",
    "    keep_failed = True,\n",
    "    keep_listener_turns = True,\n",
    "    keep_non_human = True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original data\n",
    "data_file_path = osp.join(args.originaldata_location, 'filteredCorpus.csv')\n",
    "data = build_data_dict(data_file_path) \n",
    "\n",
    "# filtering original data based on args\n",
    "data = filter_raw_data(data, args)\n",
    "\n",
    "# reformat\n",
    "data = create_final_data_sctructure(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = osp.join(config.data_dir, 'color_patch_data.json')\n",
    "with open(out_path, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context_representations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91c4f0f718960e74a34e94f60c9327bdaa5e00dda34aae6e85cb083f37da15e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
